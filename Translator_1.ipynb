{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS_583-Homework_2 .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUsYenWti6AW",
        "outputId": "5a9251cd-e077-45a5-ed96-95de73e9998a"
      },
      "source": [
        "!pip install torch torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Mqumypzryqu"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3puivnM8kr0I"
      },
      "source": [
        "import os\n",
        "import pdb\n",
        "import argparse\n",
        "import pickle as pkl\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from six.moves.urllib.request import urlretrieve\n",
        "import tarfile\n",
        "import pickle\n",
        "import sys"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNaDfrvQrEI8"
      },
      "source": [
        "# Loading the Data, Data Preprocessing, Train and Loss Functions, Train-Test Split (Question 3)\n",
        "#(Professors 'Utils' and 'Attention_nmt' files copy). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQbdyOhEkufo"
      },
      "source": [
        "class AttrDict(dict):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(AttrDict, self).__init__(*args, **kwargs)\n",
        "        self.__dict__ = self\n",
        "        \n",
        "def to_var(tensor, cuda):\n",
        "    \"\"\"Wraps a Tensor in a Variable, optionally placing it on the GPU.\n",
        "\n",
        "        Arguments:\n",
        "            tensor: A Tensor object.\n",
        "            cuda: A boolean flag indicating whether to use the GPU.\n",
        "\n",
        "        Returns:\n",
        "            A Variable object, on the GPU if cuda==True.\n",
        "    \"\"\"\n",
        "    if cuda:\n",
        "        return Variable(tensor.cuda())\n",
        "    else:\n",
        "        return Variable(tensor)\n",
        "\n",
        "\n",
        "def create_dir_if_not_exists(directory):\n",
        "    \"\"\"Creates a directory if it doesn't already exist.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "\n",
        "def save_loss_plot(train_losses, val_losses, opts):\n",
        "    \"\"\"Saves a plot of the training and validation loss curves.\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    plt.plot(range(len(train_losses)), train_losses)\n",
        "    plt.plot(range(len(val_losses)), val_losses)\n",
        "    plt.title('BS={}, nhid={}'.format(opts.batch_size, opts.hidden_size), fontsize=20)\n",
        "    plt.xlabel('Epochs', fontsize=16)\n",
        "    plt.ylabel('Loss', fontsize=16)\n",
        "    plt.xticks(fontsize=14)\n",
        "    plt.yticks(fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(opts.checkpoint_path, 'loss_plot.pdf'))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def checkpoint(encoder, decoder, idx_dict, opts):\n",
        "    \"\"\"Saves the current encoder and decoder models, along with idx_dict, which\n",
        "    contains the char_to_index and index_to_char mappings, and the start_token\n",
        "    and end_token values.\n",
        "    \"\"\"\n",
        "    with open(os.path.join(opts.checkpoint_path, 'encoder.pt'), 'wb') as f:\n",
        "        torch.save(encoder, f)\n",
        "\n",
        "    with open(os.path.join(opts.checkpoint_path, 'decoder.pt'), 'wb') as f:\n",
        "        torch.save(decoder, f)\n",
        "\n",
        "    with open(os.path.join(opts.checkpoint_path, 'idx_dict.pkl'), 'wb') as f:\n",
        "        pkl.dump(idx_dict, f)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nc2avVaitE9"
      },
      "source": [
        "def read_lines(filename):\n",
        "    \"\"\"Read a file and split it into lines.\n",
        "    \"\"\"\n",
        "    lines = open(filename).read().strip().lower().split('\\n')\n",
        "    return lines"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pfqow6lri1Or"
      },
      "source": [
        "def read_pairs(filename):\n",
        "    \"\"\"Reads lines that consist of two words, separated by a space.\n",
        "\n",
        "    Returns:\n",
        "        source_words: A list of the first word in each line of the file.\n",
        "        target_words: A list of the second word in each line of the file.\n",
        "    \"\"\"\n",
        "    lines = read_lines(filename)\n",
        "    source_words, target_words = [], []\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            source, target = line.split()\n",
        "            source_words.append(source)\n",
        "            target_words.append(target)\n",
        "    return source_words, target_words"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJAD_ZfqjpaF"
      },
      "source": [
        "def all_alpha_or_dash(s):\n",
        "    \"\"\"Helper function to check whether a string is alphabetic, allowing dashes '-'.\n",
        "    \"\"\"\n",
        "    return all(c.isalpha() or c == '-' for c in s)\n",
        "\n",
        "\n",
        "def filter_lines(lines):\n",
        "    \"\"\"Filters lines to consist of only alphabetic characters or dashes \"-\".\n",
        "    \"\"\"\n",
        "    return [line for line in lines if all_alpha_or_dash(line)]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGrstHRMjt26"
      },
      "source": [
        "def load_data():\n",
        "    \"\"\"Loads (English, Pig-Latin) word pairs, and creates mappings from characters to indexes.\n",
        "    \"\"\"\n",
        "\n",
        "    source_lines, target_lines = read_pairs('data.txt')\n",
        "\n",
        "    # Filter lines\n",
        "    source_lines = filter_lines(source_lines)\n",
        "    target_lines = filter_lines(target_lines)\n",
        "\n",
        "    all_characters = set(''.join(source_lines)) | set(''.join(target_lines))\n",
        "\n",
        "    # Create a dictionary mapping each character to a unique index\n",
        "    char_to_index = { char: index for (index, char) in enumerate(sorted(list(all_characters))) }\n",
        "\n",
        "    # Add start and end tokens to the dictionary\n",
        "    start_token = len(char_to_index)\n",
        "    end_token = len(char_to_index) + 1\n",
        "    char_to_index['SOS'] = start_token\n",
        "    char_to_index['EOS'] = end_token\n",
        "\n",
        "    # Create the inverse mapping, from indexes to characters (used to decode the model's predictions)\n",
        "    index_to_char = { index: char for (char, index) in char_to_index.items() }\n",
        "\n",
        "    # Store the final size of the vocabulary\n",
        "    vocab_size = len(char_to_index)\n",
        "\n",
        "    line_pairs = list(set(zip(source_lines, target_lines)))  # Python 3\n",
        "\n",
        "    idx_dict = { 'char_to_index': char_to_index,\n",
        "                 'index_to_char': index_to_char,\n",
        "                 'start_token': start_token,\n",
        "                 'end_token': end_token }\n",
        "\n",
        "    return line_pairs, vocab_size, idx_dict"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyR1-d5ijy9f"
      },
      "source": [
        "def create_dict(pairs):\n",
        "    \"\"\"Creates a mapping { (source_length, target_length): [list of (source, target) pairs]\n",
        "    This is used to make batches: each batch consists of two parallel tensors, one containing\n",
        "    all source indexes and the other containing all corresponding target indexes.\n",
        "    Within a batch, all the source words are the same length, and all the target words are\n",
        "    the same length.\n",
        "    \"\"\"\n",
        "    unique_pairs = list(set(pairs))  # Find all unique (source, target) pairs\n",
        "\n",
        "    d = defaultdict(list)\n",
        "    for (s,t) in unique_pairs:\n",
        "        d[(len(s), len(t))].append((s,t))\n",
        "\n",
        "    return d"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj8wkn9Tj9uw"
      },
      "source": [
        "def string_to_index_list(s, char_to_index, end_token):\n",
        "    \"\"\"Converts a sentence into a list of indexes (for each character).\n",
        "    \"\"\"\n",
        "    return [char_to_index[char] for char in s] + [end_token]  # Adds the end token to each index list\n",
        "\n",
        "\n",
        "def translate_sentence(sentence, encoder, decoder, idx_dict, opts):\n",
        "    \"\"\"Translates a sentence from English to Pig-Latin, by splitting the sentence into\n",
        "    words (whitespace-separated), running the encoder-decoder model to translate each\n",
        "    word independently, and then stitching the words back together with spaces between them.\n",
        "    \"\"\"\n",
        "    if idx_dict is None:\n",
        "      line_pairs, vocab_size, idx_dict = load_data()\n",
        "    return ' '.join([translate(word, encoder, decoder, idx_dict, opts) for word in sentence.split()])\n",
        "\n",
        "\n",
        "def translate(input_string, encoder, decoder, idx_dict, opts):\n",
        "    \"\"\"Translates a given string from English to Pig-Latin.\n",
        "    \"\"\"\n",
        "\n",
        "    char_to_index = idx_dict['char_to_index']\n",
        "    index_to_char = idx_dict['index_to_char']\n",
        "    start_token = idx_dict['start_token']\n",
        "    end_token = idx_dict['end_token']\n",
        "\n",
        "    max_generated_chars = 20\n",
        "    gen_string = ''\n",
        "\n",
        "    indexes = string_to_index_list(input_string, char_to_index, end_token)\n",
        "    indexes = to_var(torch.LongTensor(indexes).unsqueeze(0), opts.cuda)  # Unsqueeze to make it like BS = 1\n",
        "\n",
        "    encoder_annotations, encoder_last_hidden = encoder(indexes)\n",
        "\n",
        "    decoder_hidden = encoder_last_hidden\n",
        "    decoder_input = to_var(torch.LongTensor([[start_token]]), opts.cuda)  # For BS = 1\n",
        "    decoder_inputs = decoder_input\n",
        "\n",
        "    for i in range(max_generated_chars):\n",
        "      ## slow decoding, recompute everything at each time\n",
        "      decoder_outputs, attention_weights = decoder(decoder_inputs, encoder_annotations, decoder_hidden)\n",
        "      generated_words = F.softmax(decoder_outputs, dim=2).max(2)[1]\n",
        "      ni = generated_words.cpu().numpy().reshape(-1)  # LongTensor of size 1\n",
        "      ni = ni[-1] #latest output token\n",
        "\n",
        "      decoder_inputs = torch.cat([decoder_input, generated_words], dim=1)\n",
        "      \n",
        "      if ni == end_token:\n",
        "          break\n",
        "      else:\n",
        "          gen_string = \"\".join(\n",
        "              [index_to_char[int(item)] \n",
        "               for item in generated_words.cpu().numpy().reshape(-1)])\n",
        "\n",
        "    return gen_string\n",
        "\n",
        "\n",
        "def visualize_attention(input_string, encoder, decoder, idx_dict, opts):\n",
        "    \"\"\"Generates a heatmap to show where attention is focused in each decoder step.\n",
        "    \"\"\"\n",
        "    if idx_dict is None:\n",
        "      line_pairs, vocab_size, idx_dict = load_data()\n",
        "    char_to_index = idx_dict['char_to_index']\n",
        "    index_to_char = idx_dict['index_to_char']\n",
        "    start_token = idx_dict['start_token']\n",
        "    end_token = idx_dict['end_token']\n",
        "\n",
        "    max_generated_chars = 20\n",
        "    gen_string = ''\n",
        "\n",
        "    indexes = string_to_index_list(input_string, char_to_index, end_token)\n",
        "    indexes = to_var(torch.LongTensor(indexes).unsqueeze(0), opts.cuda)  # Unsqueeze to make it like BS = 1\n",
        "\n",
        "    encoder_annotations, encoder_hidden = encoder(indexes)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoder_input = to_var(torch.LongTensor([[start_token]]), opts.cuda)  # For BS = 1\n",
        "    decoder_inputs = decoder_input\n",
        "\n",
        "    produced_end_token = False\n",
        "\n",
        "    for i in range(max_generated_chars):\n",
        "      ## slow decoding, recompute everything at each time\n",
        "      decoder_outputs, attention_weights = decoder(decoder_inputs, encoder_annotations, decoder_hidden)\n",
        "      generated_words = F.softmax(decoder_outputs, dim=2).max(2)[1]\n",
        "      ni = generated_words.cpu().numpy().reshape(-1)  # LongTensor of size 1\n",
        "      ni = ni[-1] #latest output token\n",
        "      \n",
        "      decoder_inputs = torch.cat([decoder_input, generated_words], dim=1)\n",
        "      \n",
        "      if ni == end_token:\n",
        "          break\n",
        "      else:\n",
        "          gen_string = \"\".join(\n",
        "              [index_to_char[int(item)] \n",
        "               for item in generated_words.cpu().numpy().reshape(-1)])\n",
        "    \n",
        "    if isinstance(attention_weights, tuple):\n",
        "      ## transformer's attention mweights\n",
        "      attention_weights, self_attention_weights = attention_weights\n",
        "    \n",
        "    all_attention_weights = attention_weights.data.cpu().numpy()\n",
        "    \n",
        "    for i in range(len(all_attention_weights)):\n",
        "      attention_weights_matrix = all_attention_weights[i].squeeze()\n",
        "      fig = plt.figure()\n",
        "      ax = fig.add_subplot(111)\n",
        "      cax = ax.matshow(attention_weights_matrix, cmap='bone')\n",
        "      fig.colorbar(cax)\n",
        "\n",
        "      # Set up axes\n",
        "      ax.set_yticklabels([''] + list(input_string) + ['EOS'], rotation=90)\n",
        "      ax.set_xticklabels([''] + list(gen_string) + (['EOS'] if produced_end_token else []))\n",
        "\n",
        "      # Show label at every tick\n",
        "      ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "      ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "      # Add title\n",
        "      plt.xlabel('Attention weights to the source sentence in layer {}'.format(i+1))\n",
        "      plt.tight_layout()\n",
        "      plt.grid('off')\n",
        "      plt.show()\n",
        "      #plt.savefig(save)\n",
        "\n",
        "      #plt.close(fig)\n",
        "\n",
        "    return gen_string\n",
        "\n",
        "\n",
        "def compute_loss(data_dict, encoder, decoder, idx_dict, criterion, optimizer, opts):\n",
        "    \"\"\"Train/Evaluate the model on a dataset.\n",
        "\n",
        "    Arguments:\n",
        "        data_dict: The validation/test word pairs, organized by source and target lengths.\n",
        "        encoder: An encoder model to produce annotations for each step of the input sequence.\n",
        "        decoder: A decoder model (with or without attention) to generate output tokens.\n",
        "        idx_dict: Contains char-to-index and index-to-char mappings, and start & end token indexes.\n",
        "        criterion: Used to compute the CrossEntropyLoss for each decoder output.\n",
        "        optimizer: Train the weights if an optimizer is given. None if only evaluate the model. \n",
        "        opts: The command-line arguments.\n",
        "\n",
        "    Returns:\n",
        "        mean_loss: The average loss over all batches from data_dict.\n",
        "    \"\"\"\n",
        "    start_token = idx_dict['start_token']\n",
        "    end_token = idx_dict['end_token']\n",
        "    char_to_index = idx_dict['char_to_index']\n",
        "\n",
        "    losses = []\n",
        "    for key in data_dict:\n",
        "        input_strings, target_strings = zip(*data_dict[key])\n",
        "        input_tensors = [torch.LongTensor(string_to_index_list(s, char_to_index, end_token)) for s in input_strings]\n",
        "        target_tensors = [torch.LongTensor(string_to_index_list(s, char_to_index, end_token)) for s in target_strings]\n",
        "\n",
        "        num_tensors = len(input_tensors)\n",
        "        num_batches = int(np.ceil(num_tensors / float(opts.batch_size)))\n",
        "\n",
        "        for i in range(num_batches):\n",
        "\n",
        "            start = i * opts.batch_size\n",
        "            end = start + opts.batch_size\n",
        "\n",
        "            inputs = to_var(torch.stack(input_tensors[start:end]), opts.cuda)\n",
        "            targets = to_var(torch.stack(target_tensors[start:end]), opts.cuda)\n",
        "\n",
        "            # The batch size may be different in each epoch\n",
        "            BS = inputs.size(0)\n",
        "\n",
        "            encoder_annotations, encoder_hidden = encoder(inputs)\n",
        "\n",
        "            # The last hidden state of the encoder becomes the first hidden state of the decoder\n",
        "            decoder_hidden = encoder_hidden\n",
        "\n",
        "            start_vector = torch.ones(BS).long().unsqueeze(1) * start_token  # BS x 1 --> 16x1  CHECKED\n",
        "            decoder_input = to_var(start_vector, opts.cuda)  # BS x 1 --> 16x1  CHECKED\n",
        "\n",
        "            loss = 0.0\n",
        "\n",
        "            seq_len = targets.size(1)  # Gets seq_len from BS x seq_len\n",
        "\n",
        "            decoder_inputs = torch.cat([decoder_input, targets[:, 0:-1]], dim=1)  # Gets decoder inputs by shifting the targets to the right \n",
        "            \n",
        "            decoder_outputs, attention_weights = decoder(decoder_inputs, encoder_annotations, encoder_hidden)\n",
        "            decoder_outputs_flatten = decoder_outputs.view(-1, decoder_outputs.size(2))\n",
        "            targets_flatten = targets.view(-1)\n",
        "            loss = criterion(decoder_outputs_flatten, targets_flatten)\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            ## training if an optimizer is provided\n",
        "            if optimizer:\n",
        "              # Zero gradients\n",
        "              optimizer.zero_grad()\n",
        "              # Compute gradients\n",
        "              loss.backward()\n",
        "              # Update the parameters of the encoder and decoder\n",
        "              optimizer.step()\n",
        "              \n",
        "    mean_loss = np.mean(losses)\n",
        "    return mean_loss\n",
        "\n",
        "  \n",
        "\n",
        "def training_loop(train_dict, val_dict, idx_dict, encoder, decoder, criterion, optimizer, opts):\n",
        "    \"\"\"Runs the main training loop; evaluates the model on the val set every epoch.\n",
        "        * Prints training and val loss each epoch.\n",
        "        * Prints qualitative translation results each epoch using TEST_SENTENCE\n",
        "        * Saves an attention map for TEST_WORD_ATTN each epoch\n",
        "\n",
        "    Arguments:\n",
        "        train_dict: The training word pairs, organized by source and target lengths.\n",
        "        val_dict: The validation word pairs, organized by source and target lengths.\n",
        "        idx_dict: Contains char-to-index and index-to-char mappings, and start & end token indexes.\n",
        "        encoder: An encoder model to produce annotations for each step of the input sequence.\n",
        "        decoder: A decoder model (with or without attention) to generate output tokens.\n",
        "        criterion: Used to compute the CrossEntropyLoss for each decoder output.\n",
        "        optimizer: Implements a step rule to update the parameters of the encoder and decoder.\n",
        "        opts: The command-line arguments.\n",
        "    \"\"\"\n",
        "\n",
        "    start_token = idx_dict['start_token']\n",
        "    end_token = idx_dict['end_token']\n",
        "    char_to_index = idx_dict['char_to_index']\n",
        "\n",
        "    loss_log = open(os.path.join(opts.checkpoint_path, 'loss_log.txt'), 'w')\n",
        "\n",
        "    best_val_loss = 1e6\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(opts.nepochs):\n",
        "\n",
        "        optimizer.param_groups[0]['lr'] *= opts.lr_decay\n",
        "        \n",
        "        train_loss = compute_loss(train_dict, encoder, decoder, idx_dict, criterion, optimizer, opts)\n",
        "        val_loss = compute_loss(val_dict, encoder, decoder, idx_dict, criterion, None, opts)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            checkpoint(encoder, decoder, idx_dict, opts)\n",
        "\n",
        "        gen_string = translate_sentence(TEST_SENTENCE, encoder, decoder, idx_dict, opts)\n",
        "        print(\"Epoch: {:3d} | Train loss: {:.3f} | Val loss: {:.3f} | Gen: {:20s}\".format(epoch, train_loss, val_loss, gen_string))\n",
        "\n",
        "        loss_log.write('{} {} {}\\n'.format(epoch, train_loss, val_loss))\n",
        "        loss_log.flush()\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        save_loss_plot(train_losses, val_losses, opts)\n",
        "\n",
        "\n",
        "def print_data_stats(line_pairs, vocab_size, idx_dict):\n",
        "    \"\"\"Prints example word pairs, the number of data points, and the vocabulary.\n",
        "    \"\"\"\n",
        "    print('=' * 80)\n",
        "    print('Data Stats'.center(80))\n",
        "    print('-' * 80)\n",
        "    for pair in line_pairs[:5]:\n",
        "        print(pair)\n",
        "    print('Num unique word pairs: {}'.format(len(line_pairs)))\n",
        "    print('Vocabulary: {}'.format(idx_dict['char_to_index'].keys()))\n",
        "    print('Vocab size: {}'.format(vocab_size))\n",
        "    print('=' * 80)\n",
        "\n",
        "\n",
        "def train(opts):\n",
        "    line_pairs, vocab_size, idx_dict = load_data()\n",
        "    print_data_stats(line_pairs, vocab_size, idx_dict)\n",
        "\n",
        "    # Split the line pairs into an 80% train and 20% val split\n",
        "    num_lines = len(line_pairs)\n",
        "    num_train = int(0.8 * num_lines)\n",
        "    train_pairs, val_pairs = line_pairs[:num_train], line_pairs[num_train:]\n",
        "\n",
        "    # Group the data by the lengths of the source and target words, to form batches\n",
        "    train_dict = create_dict(train_pairs)\n",
        "    val_dict = create_dict(val_pairs)\n",
        "\n",
        "    ##########################################################################\n",
        "    ### Setup: Create Encoder, Decoder, Learning Criterion, and Optimizers ###\n",
        "    ##########################################################################\n",
        "    if opts.encoder_type == \"rnn\":\n",
        "      encoder = GRUEncoder(vocab_size=vocab_size, \n",
        "                          hidden_size=opts.hidden_size, \n",
        "                          opts=opts)\n",
        "    elif opts.encoder_type == \"transformer\":\n",
        "      encoder = TransformerEncoder(vocab_size=vocab_size, \n",
        "                                   hidden_size=opts.hidden_size, \n",
        "                                   num_layers=opts.num_transformer_layers,\n",
        "                                   opts=opts)\n",
        "    else:\n",
        "        print(\"why is it here\")\n",
        "        raise NotImplementedError\n",
        "\n",
        "    if opts.decoder_type == 'rnn':\n",
        "        decoder = NoAttentionDecoder(vocab_size=vocab_size, \n",
        "                             hidden_size=opts.hidden_size)\n",
        "    elif opts.decoder_type == 'rnn_attention':\n",
        "        decoder = AttentionDecoder(vocab_size=vocab_size, \n",
        "                                      hidden_size=opts.hidden_size, \n",
        "                                      attention_type=opts.attention_type)\n",
        "    elif opts.decoder_type == 'transformer':\n",
        "        decoder = TransformerDecoder(vocab_size=vocab_size, \n",
        "                                     hidden_size=opts.hidden_size, \n",
        "                                     num_layers=opts.num_transformer_layers)\n",
        "    else:\n",
        "        print(\"why is it here\")\n",
        "        raise NotImplementedError\n",
        "        \n",
        "    #### setup checkpoint path\n",
        "    model_name = 'h{}-bs{}-{}'.format(opts.hidden_size, \n",
        "                                      opts.batch_size, \n",
        "                                      opts.decoder_type)\n",
        "    opts.checkpoint_path = model_name\n",
        "    create_dir_if_not_exists(opts.checkpoint_path)\n",
        "    ####\n",
        "\n",
        "    if opts.cuda:\n",
        "        encoder.cuda()\n",
        "        decoder.cuda()\n",
        "        print(\"Moved models to GPU!\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=opts.learning_rate)\n",
        "\n",
        "    try:\n",
        "        training_loop(train_dict, val_dict, idx_dict, encoder, decoder, criterion, optimizer, opts)\n",
        "    except KeyboardInterrupt:\n",
        "        print('Exiting early from training.')\n",
        "        return encoder, decoder\n",
        "      \n",
        "    return encoder, decoder\n",
        "\n",
        "\n",
        "def print_opts(opts):\n",
        "    \"\"\"Prints the values of all command-line arguments.\n",
        "    \"\"\"\n",
        "    print('=' * 80)\n",
        "    print('Opts'.center(80))\n",
        "    print('-' * 80)\n",
        "    for key in opts.__dict__:\n",
        "        print('{:>30}: {:<30}'.format(key, opts.__dict__[key]).center(80))\n",
        "    print('=' * 80)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hck-xiVsEz6"
      },
      "source": [
        "# GRU Model- RNN based Encoder/Decoder (Question 1, 2 & 3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-eyoMa_k6ZI"
      },
      "source": [
        "class MyGRUCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(MyGRUCell, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # ------------\n",
        "        # FILL THIS IN\n",
        "        # ------------\n",
        "        ## Input linear layers\n",
        "        self.Wiz = nn.Linear(input_size, hidden_size)\n",
        "        self.Wir = nn.Linear(input_size, hidden_size)\n",
        "        self.Wih = nn.Linear(input_size, hidden_size)\n",
        "\n",
        "        ## Hidden linear layers\n",
        "        self.Whz = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Whr = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Whh = nn.Linear(hidden_size, hidden_size)\n",
        "        \n",
        "\n",
        "    def forward(self, x, h_prev):\n",
        "        \"\"\"Forward pass of the GRU computation for one time step.\n",
        "\n",
        "        Arguments\n",
        "            x: batch_size x input_size\n",
        "            h_prev: batch_size x hidden_size\n",
        "\n",
        "        Returns:\n",
        "            h_new: batch_size x hidden_size\n",
        "        \"\"\"\n",
        "\n",
        "        # ------------\n",
        "        # FILL THIS IN\n",
        "        # ------------\n",
        "        z = torch.sigmoid(self.Wiz(x) + self.Whz(h_prev))\n",
        "        r = torch.sigmoid(self.Wir(x) + self.Whr(h_prev))\n",
        "        g = torch.tanh(self.Wih(x) * self.Whh(h_prev))\n",
        "        h_new = (1-z) * g + z * h_prev\n",
        "        return h_new"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxQfhSScl8k1"
      },
      "source": [
        "class GRUEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, opts):\n",
        "        super(GRUEncoder, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.opts = opts\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.gru = MyGRUCell(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"Forward pass of the encoder RNN.\n",
        "\n",
        "        Arguments:\n",
        "            inputs: Input token indexes across a batch for all time steps in the sequence. (batch_size x seq_len)\n",
        "\n",
        "        Returns:\n",
        "            annotations: The hidden states computed at each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
        "            hidden: The final hidden state of the encoder, for each sequence in a batch. (batch_size x hidden_size)\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size, seq_len = inputs.size()\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        encoded = self.embedding(inputs)  # batch_size x seq_len x hidden_size\n",
        "        annotations = []\n",
        "\n",
        "        for i in range(seq_len):\n",
        "            x = encoded[:,i,:]  # Get the current time step, across the whole batch\n",
        "            hidden = self.gru(x, hidden)\n",
        "            annotations.append(hidden)\n",
        "\n",
        "        annotations = torch.stack(annotations, dim=1)\n",
        "        return annotations, hidden\n",
        "\n",
        "    def init_hidden(self, bs):\n",
        "        \"\"\"Creates a tensor of zeros to represent the initial hidden states\n",
        "        of a batch of sequences.\n",
        "\n",
        "        Arguments:\n",
        "            bs: The batch size for the initial hidden state.\n",
        "\n",
        "        Returns:\n",
        "            hidden: An initial hidden state of all zeros. (batch_size x hidden_size)\n",
        "        \"\"\"\n",
        "        return to_var(torch.zeros(bs, self.hidden_size), self.opts.cuda)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZuGMIBXl_Y9"
      },
      "source": [
        "class NoAttentionDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size):\n",
        "        super(NoAttentionDecoder, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.rnn = MyGRUCell(input_size=hidden_size, hidden_size=hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, inputs, annotations, hidden_init):\n",
        "        \"\"\"Forward pass of the non-attentional decoder RNN.\n",
        "\n",
        "        Arguments:\n",
        "            inputs: Input token indexes across a batch. (batch_size x seq_len)\n",
        "            annotations: This is not used here. It just maintains consistency with the\n",
        "                    interface used by the AttentionDecoder class.\n",
        "            hidden_init: The hidden states from the last step of encoder, across a batch. (batch_size x hidden_size)\n",
        "\n",
        "        Returns:\n",
        "            output: Un-normalized scores for each token in the vocabulary, across a batch for all the decoding time steps. (batch_size x decoder_seq_len x vocab_size)\n",
        "            None        \n",
        "        \"\"\"        \n",
        "        batch_size, seq_len = inputs.size()\n",
        "        embed = self.embedding(inputs)  # batch_size x seq_len x hidden_size        \n",
        "\n",
        "        hiddens = []\n",
        "        h_prev = hidden_init\n",
        "        for i in range(seq_len):\n",
        "            x = embed[:,i,:]  # Get the current time step input tokens, across the whole batch\n",
        "            h_prev = self.rnn(x, h_prev)  # batch_size x hidden_size\n",
        "            hiddens.append(h_prev)\n",
        "\n",
        "        hiddens = torch.stack(hiddens, dim=1) # batch_size x seq_len x hidden_size\n",
        "        \n",
        "        output = self.out(hiddens)  # batch_size x seq_len x vocab_size\n",
        "        return output, None"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtN2smhFmDr5"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXh2nQJQmNEO",
        "outputId": "141b83ca-258c-4bb4-e7e7-4f08fde38cb9"
      },
      "source": [
        "TEST_SENTENCE = 'the air conditioning is working'\n",
        "\n",
        "args = AttrDict()\n",
        "args_dict = {\n",
        "              'cuda':True, \n",
        "              'nepochs':100, \n",
        "              'checkpoint_dir':\"checkpoints\", \n",
        "              'learning_rate':0.005, \n",
        "              'lr_decay':0.99,\n",
        "              'batch_size':64, \n",
        "              'hidden_size':20, \n",
        "              'encoder_type': 'rnn',\n",
        "              'decoder_type': 'rnn', \n",
        "              'attention_type': '',  \n",
        "}\n",
        "args.update(args_dict)\n",
        "\n",
        "print_opts(args)\n",
        "rnn_encoder, NoAttentionDecoder = train(args)\n",
        "\n",
        "translated = translate_sentence(TEST_SENTENCE, rnn_encoder, NoAttentionDecoder, None, args)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                                   cuda: 1                                      \n",
            "                                nepochs: 100                                    \n",
            "                         checkpoint_dir: checkpoints                            \n",
            "                          learning_rate: 0.005                                  \n",
            "                               lr_decay: 0.99                                   \n",
            "                             batch_size: 64                                     \n",
            "                            hidden_size: 20                                     \n",
            "                           encoder_type: rnn                                    \n",
            "                           decoder_type: rnn                                    \n",
            "                         attention_type:                                        \n",
            "================================================================================\n",
            "================================================================================\n",
            "                                   Data Stats                                   \n",
            "--------------------------------------------------------------------------------\n",
            "('conformity', 'onformitycay')\n",
            "('accounted', 'accountedway')\n",
            "('slept', 'eptslay')\n",
            "('outward', 'outwardway')\n",
            "('breakfast', 'eakfastbray')\n",
            "Num unique word pairs: 6387\n",
            "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
            "Vocab size: 29\n",
            "================================================================================\n",
            "Moved models to GPU!\n",
            "Epoch:   0 | Train loss: 2.368 | Val loss: 2.040 | Gen: ensay ay entay entay entay\n",
            "Epoch:   1 | Train loss: 1.935 | Val loss: 1.925 | Gen: artay-intay-ingway-i artay-intay-ingway-i eseray-intay-ingway- estay-ingway-intay-i eseray-intay-ingway-\n",
            "Epoch:   2 | Train loss: 1.839 | Val loss: 1.849 | Gen: eray away ontingway ingway ontingway\n",
            "Epoch:   3 | Train loss: 1.733 | Val loss: 1.789 | Gen: eay-estay-ingway away estingway ingway estertay-ingway\n",
            "Epoch:   4 | Train loss: 1.665 | Val loss: 1.765 | Gen: eay-estay-ingway away inconsingway ingay-ingway onsedway\n",
            "Epoch:   5 | Train loss: 1.617 | Val loss: 1.754 | Gen: eay-ingay-ingay-inga away estintintedway intay-ingay-ingay-in oneray-ingay-ingay-i\n",
            "Epoch:   6 | Train loss: 1.586 | Val loss: 1.713 | Gen: eay-ingway away estingway ingay-ingway oneray-ingway\n",
            "Epoch:   7 | Train loss: 1.546 | Val loss: 1.689 | Gen: eay-ingway away-away-ingway onerssay-ingway ingay-ingway onersay-ingway\n",
            "Epoch:   8 | Train loss: 1.535 | Val loss: 1.692 | Gen: eayday arsay-ingway onerssay-ingway ingay-ontay-ay-ay-ay onterssay-ingway\n",
            "Epoch:   9 | Train loss: 1.496 | Val loss: 1.659 | Gen: eayday arssay-ingway onensingway ingay-ontay-ingway-a onerstay-ingedway\n",
            "Epoch:  10 | Train loss: 1.471 | Val loss: 1.644 | Gen: eay-edway arssay-ineway onensingway ingay-oway insinglingay-ineway\n",
            "Epoch:  11 | Train loss: 1.447 | Val loss: 1.643 | Gen: eay-oday arllay-ineway onensingway ingay-ingway-ayday ortingedway\n",
            "Epoch:  12 | Train loss: 1.428 | Val loss: 1.650 | Gen: eay-oday arsay-ingway-ayday ongestedway istay-ingway-ayday ortingway-ingway-ayd\n",
            "Epoch:  13 | Train loss: 1.454 | Val loss: 1.600 | Gen: eayday arlay-inway-away-ine ongay-inway-awlay ingay orstay-inway-away-in\n",
            "Epoch:  14 | Train loss: 1.416 | Val loss: 1.596 | Gen: etay-oway arlay-estay-ineway onsedway-awlay ingway illfingway-awlay\n",
            "Epoch:  15 | Train loss: 1.388 | Val loss: 1.561 | Gen: eay-ayday arsay-estay-ineway ongestedway inway orstay-inway-awlay\n",
            "Epoch:  16 | Train loss: 1.365 | Val loss: 1.573 | Gen: eayday arlingway onsonsway-ineway inglay illfingway-awlay\n",
            "Epoch:  17 | Train loss: 1.356 | Val loss: 1.579 | Gen: etay arsay-inway-awlay ongestedway-ineway inway orsinglay-awlay\n",
            "Epoch:  18 | Train loss: 1.346 | Val loss: 1.549 | Gen: ehay arlinway-awlay onsedway-ineway inway insinsinsedway\n",
            "Epoch:  19 | Train loss: 1.328 | Val loss: 1.511 | Gen: etay arsay-inway-awlay onsedway-ingway isway insay-onsincoushay-a\n",
            "Epoch:  20 | Train loss: 1.325 | Val loss: 1.622 | Gen: ehay arlingway-ineway onsinglay-ineway issay-edway insinsinglay-ineway\n",
            "Epoch:  21 | Train loss: 1.342 | Val loss: 1.507 | Gen: etay arlingway onsedway-ingway-ay-a issay orsay-inway-awlay\n",
            "Epoch:  22 | Train loss: 1.328 | Val loss: 1.524 | Gen: eeday arlingway onsonsedway ishay orsinglay\n",
            "Epoch:  23 | Train loss: 1.334 | Val loss: 1.502 | Gen: etay arsay-inway-awlay onsonsedway inway inlinsedway\n",
            "Epoch:  24 | Train loss: 1.300 | Val loss: 1.502 | Gen: etay arsay-ingway onsonsinglay-awlay issay-awlay inlinsay-inway-awlay\n",
            "Epoch:  25 | Train loss: 1.279 | Val loss: 1.467 | Gen: ehedway arsay-ondedway onsonsedway issay inlisway-ingway\n",
            "Epoch:  26 | Train loss: 1.265 | Val loss: 1.457 | Gen: ehedway arlingway onsonsedway issay inlistsay-ingway-ayd\n",
            "Epoch:  27 | Train loss: 1.254 | Val loss: 1.482 | Gen: etay arsinglay onsinsinglay issay orsinsinglay\n",
            "Epoch:  28 | Train loss: 1.253 | Val loss: 1.488 | Gen: etay arsinglay onsonsinglay-awlay issway insinsinglay-awlay\n",
            "Epoch:  29 | Train loss: 1.243 | Val loss: 1.479 | Gen: ehedgay arsay-inway-awlay onsinsinglay isway orsinsingway\n",
            "Epoch:  30 | Train loss: 1.258 | Val loss: 1.482 | Gen: etay allway-ingway onsonstay-inway-inew issway orsinglyway\n",
            "Epoch:  31 | Train loss: 1.253 | Val loss: 1.445 | Gen: eheday airpray onsinglyway isway orsincesway\n",
            "Epoch:  32 | Train loss: 1.227 | Val loss: 1.434 | Gen: ehedgay arsingway onsonsinglyway isway onsinsinglay-away-ay\n",
            "Epoch:  33 | Train loss: 1.216 | Val loss: 1.423 | Gen: ehedgay airway onsonsinglay isway orsinglay\n",
            "Epoch:  34 | Train loss: 1.206 | Val loss: 1.428 | Gen: eheday airpray onsinsinglay-awlay isway orsincenay-awlay\n",
            "Epoch:  35 | Train loss: 1.202 | Val loss: 1.412 | Gen: etay airtway onsonsinglyway isway orsinglay-ingway\n",
            "Epoch:  36 | Train loss: 1.198 | Val loss: 1.447 | Gen: etay airpray onsincenay-awlay isway ornsinglay-awlay\n",
            "Epoch:  37 | Train loss: 1.197 | Val loss: 1.423 | Gen: etay airtway onsinglingway isway inlisway-ingway\n",
            "Epoch:  38 | Train loss: 1.187 | Val loss: 1.425 | Gen: etay airpray onsonsinglyway isway orsinceray-awlay\n",
            "Epoch:  39 | Train loss: 1.181 | Val loss: 1.404 | Gen: ehay airtay onsinglyway isway olgistingway\n",
            "Epoch:  40 | Train loss: 1.164 | Val loss: 1.394 | Gen: etay airtway onsonsinglyway isway olwlay-ingway\n",
            "Epoch:  41 | Train loss: 1.156 | Val loss: 1.411 | Gen: etay airtay onsinglyway isway orsinglay-ybay\n",
            "Epoch:  42 | Train loss: 1.150 | Val loss: 1.383 | Gen: ehay airpray onsinglyway isway olgilingway\n",
            "Epoch:  43 | Train loss: 1.140 | Val loss: 1.398 | Gen: etay airpay onsinglyway isway ollingray\n",
            "Epoch:  44 | Train loss: 1.160 | Val loss: 1.426 | Gen: etay allyway onsinglay-awlay ishay orsinglay-ybay\n",
            "Epoch:  45 | Train loss: 1.160 | Val loss: 1.524 | Gen: eedgay airway onconedway isway orsinglyway\n",
            "Epoch:  46 | Train loss: 1.155 | Val loss: 1.415 | Gen: etay airway onsinglyway isway orsinglay\n",
            "Epoch:  47 | Train loss: 1.133 | Val loss: 1.393 | Gen: etay airway onsinglyway isway olgicelay\n",
            "Epoch:  48 | Train loss: 1.128 | Val loss: 1.363 | Gen: etay aincay onconerway ishay oltinglay\n",
            "Epoch:  49 | Train loss: 1.119 | Val loss: 1.370 | Gen: etay airtay onconedway-ybay ishay olway-onsinglay\n",
            "Epoch:  50 | Train loss: 1.112 | Val loss: 1.391 | Gen: etay airway oncinglyway isway ormingray\n",
            "Epoch:  51 | Train loss: 1.108 | Val loss: 1.356 | Gen: etay airpay onconedway ishay ollestay-ybay\n",
            "Epoch:  52 | Train loss: 1.116 | Val loss: 1.429 | Gen: etedway airtay oncinglay isway ollinessway\n",
            "Epoch:  53 | Train loss: 1.127 | Val loss: 1.348 | Gen: etay airedway oncineway-ayday isway ollesway\n",
            "Epoch:  54 | Train loss: 1.112 | Val loss: 1.412 | Gen: etay airtway oncinglyway ishay onsillway\n",
            "Epoch:  55 | Train loss: 1.110 | Val loss: 1.376 | Gen: etay airway oncinglyway ishay orsinglay\n",
            "Epoch:  56 | Train loss: 1.092 | Val loss: 1.419 | Gen: etay airway oncingway ishay orsinglay\n",
            "Epoch:  57 | Train loss: 1.094 | Val loss: 1.330 | Gen: etay airtay onsinglyway ishay ormingway\n",
            "Epoch:  58 | Train loss: 1.082 | Val loss: 1.408 | Gen: etay airway oncinglyway isway orsinglay-inway\n",
            "Epoch:  59 | Train loss: 1.081 | Val loss: 1.343 | Gen: etay ailway oncinglyway ishay ollingray\n",
            "Epoch:  60 | Train loss: 1.069 | Val loss: 1.326 | Gen: etay airway oncintingway ishay olinessway\n",
            "Epoch:  61 | Train loss: 1.056 | Val loss: 1.367 | Gen: etay ailway oncinglay isway ollesway\n",
            "Epoch:  62 | Train loss: 1.073 | Val loss: 1.353 | Gen: etay airiday oncingingway isway ollingway\n",
            "Epoch:  63 | Train loss: 1.075 | Val loss: 1.375 | Gen: etay airway oncinglay isay ollingway\n",
            "Epoch:  64 | Train loss: 1.062 | Val loss: 1.325 | Gen: etay ailway oncinglyway ishay ollingway\n",
            "Epoch:  65 | Train loss: 1.050 | Val loss: 1.331 | Gen: etay ailway oncinglyway isway ollinglay\n",
            "Epoch:  66 | Train loss: 1.048 | Val loss: 1.308 | Gen: etay ailway oncingingway ishay ollesway\n",
            "Epoch:  67 | Train loss: 1.052 | Val loss: 1.396 | Gen: etay airtway oncinglyway isay ollingway\n",
            "Epoch:  68 | Train loss: 1.066 | Val loss: 1.321 | Gen: eetay airshay oncingionsionsway ishay ollesway\n",
            "Epoch:  69 | Train loss: 1.041 | Val loss: 1.291 | Gen: etay ailway oncintingway ishay ollesway\n",
            "Epoch:  70 | Train loss: 1.027 | Val loss: 1.294 | Gen: etay ailway oncinglyway ishay ollingsway\n",
            "Epoch:  71 | Train loss: 1.020 | Val loss: 1.281 | Gen: etay ailway ontingionsway ishay ollessway\n",
            "Epoch:  72 | Train loss: 1.014 | Val loss: 1.300 | Gen: etay ailway oncinglyway ishay ollesway\n",
            "Epoch:  73 | Train loss: 1.022 | Val loss: 1.307 | Gen: etay ailway ontingionsway iseway olinessway\n",
            "Epoch:  74 | Train loss: 1.045 | Val loss: 1.367 | Gen: etedway ailway ontingionceway isway ollinglay\n",
            "Epoch:  75 | Train loss: 1.042 | Val loss: 1.345 | Gen: ethay alingway oncingessionsway ishay ollessway\n",
            "Epoch:  76 | Train loss: 1.038 | Val loss: 1.296 | Gen: etay ailway oncintionsway isway ollingray\n",
            "Epoch:  77 | Train loss: 1.009 | Val loss: 1.285 | Gen: etay ailway ontingionsway isway ollessway\n",
            "Epoch:  78 | Train loss: 1.000 | Val loss: 1.300 | Gen: etay ailway oncintionsway isway ollesslay\n",
            "Epoch:  79 | Train loss: 0.995 | Val loss: 1.277 | Gen: etay ailway ontingionsway isway ollingray\n",
            "Epoch:  80 | Train loss: 0.990 | Val loss: 1.277 | Gen: etay ailway ondinglyway isway ollingray\n",
            "Epoch:  81 | Train loss: 0.998 | Val loss: 1.360 | Gen: etay aliway ontingionsionsway isway ollesssway\n",
            "Epoch:  82 | Train loss: 1.039 | Val loss: 1.354 | Gen: etay aliway ontingionsway isway olinesclay\n",
            "Epoch:  83 | Train loss: 1.033 | Val loss: 1.403 | Gen: etay alishay ondintionscay isway olilinessway\n",
            "Epoch:  84 | Train loss: 1.023 | Val loss: 1.301 | Gen: etedway ailway ondinglyway ishay ollingray\n",
            "Epoch:  85 | Train loss: 1.003 | Val loss: 1.295 | Gen: etay ailway oncintionsway ishay ollessway\n",
            "Epoch:  86 | Train loss: 0.992 | Val loss: 1.262 | Gen: etay ailway ondinglyway ishay ollessway\n",
            "Epoch:  87 | Train loss: 0.974 | Val loss: 1.258 | Gen: etay aliway ondinglyway ishay ollingsway\n",
            "Epoch:  88 | Train loss: 0.970 | Val loss: 1.252 | Gen: etay ailay ondinglyway ishay ollingsway\n",
            "Epoch:  89 | Train loss: 0.966 | Val loss: 1.261 | Gen: etay ailway ondinglyway isway ollingray\n",
            "Epoch:  90 | Train loss: 0.965 | Val loss: 1.265 | Gen: etay aliway oncintionsway ishay ollessway\n",
            "Epoch:  91 | Train loss: 0.967 | Val loss: 1.290 | Gen: ethay ailway ondintionscay isway orlinglay\n",
            "Epoch:  92 | Train loss: 0.976 | Val loss: 1.330 | Gen: etay ailway ondinglyway isway ollinglay\n",
            "Epoch:  93 | Train loss: 0.981 | Val loss: 1.351 | Gen: etay ailishedway oncintingingway ishay olkencessway\n",
            "Epoch:  94 | Train loss: 0.989 | Val loss: 1.321 | Gen: ethay airway ondinglyway ishay orlingray\n",
            "Epoch:  95 | Train loss: 0.995 | Val loss: 1.287 | Gen: etay ailay ondintionscay isway olkencay\n",
            "Epoch:  96 | Train loss: 0.964 | Val loss: 1.271 | Gen: etay aliway oncintinglyway isway olkenceway\n",
            "Epoch:  97 | Train loss: 0.973 | Val loss: 1.262 | Gen: ettay airway ondinglyway isway olinesclay\n",
            "Epoch:  98 | Train loss: 0.977 | Val loss: 1.252 | Gen: etay aliway ondinglyway ishay olinespray\n",
            "Epoch:  99 | Train loss: 0.964 | Val loss: 1.262 | Gen: etay aliway oncintionsway ishay orkencesway\n",
            "source:\t\tthe air conditioning is working \n",
            "translated:\tetay aliway oncintionsway ishay orkencesway\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuTrCk6AqRaJ",
        "outputId": "509a1004-de63-404c-c6f5-114301847840"
      },
      "source": [
        "TEST_SENTENCE = 'tea team tight'\n",
        "translated = translate_sentence(TEST_SENTENCE, rnn_encoder, NoAttentionDecoder, None, args)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))\n",
        "TEST_SENTENCE = 'shopping fighting running'\n",
        "translated = translate_sentence(TEST_SENTENCE, rnn_encoder, NoAttentionDecoder, None, args)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source:\t\ttea team tight \n",
            "translated:\teatway eatray ettway\n",
            "source:\t\tshopping fighting running \n",
            "translated:\toncisesway igutionsway uninglay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMBWCdVLsa8X"
      },
      "source": [
        "# Attention Model (Question 5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2z1LAwot-AU"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(Attention, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # A two layer fully-connected network\n",
        "        # hidden_size*2 --> hidden_size, ReLU, hidden_size --> 1\n",
        "        self.attention_network = nn.Sequential(\n",
        "                                    nn.Linear(hidden_size*2, hidden_size),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Linear(hidden_size, 1)\n",
        "                                 )\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, queries, keys, values):\n",
        "        \"\"\"The forward pass of the attention mechanism.\n",
        "\n",
        "        Arguments:\n",
        "            queries: The current decoder hidden state. (batch_size x hidden_size)\n",
        "            keys: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
        "            values: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
        "\n",
        "        Returns:\n",
        "            context: weighted average of the values (batch_size x 1 x hidden_size)\n",
        "            attention_weights: Normalized attention weights for each encoder hidden state. (batch_size x seq_len x 1)\n",
        "\n",
        "            The attention_weights must be a softmax weighting over the seq_len annotations.\n",
        "        \"\"\"\n",
        "        batch_size = keys.size(0)\n",
        "        expanded_queries = queries.view(batch_size, -1, self.hidden_size).expand_as(keys)\n",
        "        concat_inputs = torch.cat([expanded_queries, keys], dim=2)\n",
        "        unnormalized_attention = self.attention_network(concat_inputs)\n",
        "        attention_weights = self.softmax(unnormalized_attention)\n",
        "        context = torch.bmm(attention_weights.transpose(2,1), values)\n",
        "        return context, attention_weights"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SqXNqVcuKnG"
      },
      "source": [
        "class AttentionDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, attention_type='attention'):\n",
        "        super(AttentionDecoder, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "\n",
        "        self.rnn = MyGRUCell(input_size=hidden_size*2, hidden_size=hidden_size)\n",
        "        #if attention_type == 'attention':\n",
        "        self.attention = Attention(hidden_size=hidden_size)\n",
        "        \n",
        "        self.out = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "        \n",
        "    def forward(self, inputs, annotations, hidden_init):\n",
        "        \"\"\"Forward pass of the attention-based decoder RNN.\n",
        "\n",
        "        Arguments:\n",
        "            inputs: Input token indexes across a batch for all the time step. (batch_size x decoder_seq_len)\n",
        "            annotations: The encoder hidden states for each step of the input.\n",
        "                         sequence. (batch_size x seq_len x hidden_size)\n",
        "            hidden_init: The final hidden states from the encoder, across a batch. (batch_size x hidden_size)\n",
        "\n",
        "        Returns:\n",
        "            output: Un-normalized scores for each token in the vocabulary, across a batch for all the decoding time steps. (batch_size x decoder_seq_len x vocab_size)\n",
        "            attentions: The stacked attention weights applied to the encoder annotations (batch_size x encoder_seq_len x decoder_seq_len)\n",
        "        \"\"\"\n",
        "        \n",
        "        batch_size, seq_len = inputs.size()\n",
        "        embed = self.embedding(inputs)  # batch_size x seq_len x hidden_size        \n",
        "\n",
        "        hiddens = []\n",
        "        attentions = []\n",
        "        h_prev = hidden_init\n",
        "        for i in range(seq_len):\n",
        "            # ------------\n",
        "            # FILL THIS IN - START\n",
        "            # ------------\n",
        "            embed_current = embed[:,i,:]  # Get the current time step, across the whole batch (batch size x hidden size)\n",
        "            context, attention_weights = self.attention(embed_current, annotations, annotations)  # batch_size x 1 x hidden_size\n",
        "            embed_and_context = torch.cat([embed_current, torch.squeeze(context, dim=1)], dim=1)  # batch_size x (2*hidden_size)\n",
        "            h_prev = self.rnn(embed_and_context, h_prev)  # batch_size x hidden_size      \n",
        "            # ------------\n",
        "            # FILL THIS IN - END\n",
        "            # ------------     \n",
        "            \n",
        "            hiddens.append(h_prev)\n",
        "            attentions.append(attention_weights)\n",
        "\n",
        "        hiddens = torch.stack(hiddens, dim=1) # batch_size x seq_len x hidden_size\n",
        "        attentions = torch.cat(attentions, dim=2) # batch_size x seq_len x seq_len\n",
        "        \n",
        "        output = self.out(hiddens)  # batch_size x seq_len x vocab_size\n",
        "        return output, attentions"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAlBDFW2ue_u",
        "outputId": "3700e81f-cede-42b0-ccbf-90047504bcf0"
      },
      "source": [
        "TEST_SENTENCE = 'the air conditioning is working'\n",
        "\n",
        "args = AttrDict()\n",
        "args_dict = {\n",
        "              'cuda':True, \n",
        "              'nepochs':100, \n",
        "              'checkpoint_dir':\"checkpoints\", \n",
        "              'learning_rate':0.005, \n",
        "              'lr_decay':0.99,\n",
        "              'batch_size':64, \n",
        "              'hidden_size':20, \n",
        "              'encoder_type': 'rnn', \n",
        "              'decoder_type': 'rnn_attention', \n",
        "              'attention_type': 'attention'\n",
        "}\n",
        "args.update(args_dict)\n",
        "\n",
        "print_opts(args)\n",
        "rnn_attn_encoder, AttentionDecoder = train(args)\n",
        "\n",
        "translated = translate_sentence(TEST_SENTENCE, rnn_attn_encoder, AttentionDecoder, None, args)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                                   cuda: 1                                      \n",
            "                                nepochs: 100                                    \n",
            "                         checkpoint_dir: checkpoints                            \n",
            "                          learning_rate: 0.005                                  \n",
            "                               lr_decay: 0.99                                   \n",
            "                             batch_size: 64                                     \n",
            "                            hidden_size: 20                                     \n",
            "                           encoder_type: rnn                                    \n",
            "                           decoder_type: rnn_attention                          \n",
            "                         attention_type: attention                              \n",
            "================================================================================\n",
            "================================================================================\n",
            "                                   Data Stats                                   \n",
            "--------------------------------------------------------------------------------\n",
            "('conformity', 'onformitycay')\n",
            "('accounted', 'accountedway')\n",
            "('slept', 'eptslay')\n",
            "('outward', 'outwardway')\n",
            "('breakfast', 'eakfastbray')\n",
            "Num unique word pairs: 6387\n",
            "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
            "Vocab size: 29\n",
            "================================================================================\n",
            "Moved models to GPU!\n",
            "Epoch:   0 | Train loss: 2.359 | Val loss: 2.013 | Gen: ay ay onsay ay onsay\n",
            "Epoch:   1 | Train loss: 1.871 | Val loss: 1.882 | Gen: ay-ay-ay ay-inay onsay ay-ay onday\n",
            "Epoch:   2 | Train loss: 1.710 | Val loss: 1.757 | Gen: ay-ay-ay-ay-ay-ay-ay ay-ilay ontinsay-onsay ay-ay-ay-ay-ay onsay\n",
            "Epoch:   3 | Train loss: 1.583 | Val loss: 1.699 | Gen: atay ay-iday ongingway ay-ay-ay-ay-ay-ay-ay ordway\n",
            "Epoch:   4 | Train loss: 1.482 | Val loss: 1.626 | Gen: eay ay-iray oursionday idway oodday\n",
            "Epoch:   5 | Train loss: 1.387 | Val loss: 1.510 | Gen: eay-ay-ay-ay-ay-ay-a ay-iray-iray-aray ontay-inday isway odtay-orday\n",
            "Epoch:   6 | Train loss: 1.272 | Val loss: 1.477 | Gen: atay-alway ay-iray-iray-aray-ar oncay-inonday isway ordway-ingray-array\n",
            "Epoch:   7 | Train loss: 1.156 | Val loss: 1.381 | Gen: elay-ay-ay-ay-ay-ay- ay-iray-iray-away-aw ontay-inay-inay-onda isshay orinway-inway-inway-\n",
            "Epoch:   8 | Train loss: 1.038 | Val loss: 1.281 | Gen: eay-ay-ay-ay-ay-ay-a away-iriray oncay-iudncay isshay orway-orway\n",
            "Epoch:   9 | Train loss: 0.928 | Val loss: 1.122 | Gen: etay airay-away-away-away ongiongsay-onday ispay orway-ingay-orway\n",
            "Epoch:  10 | Train loss: 0.811 | Val loss: 1.114 | Gen: itetay away-irway oncioncay-iuncay isisway orway-ingway-orway\n",
            "Epoch:  11 | Train loss: 0.746 | Val loss: 1.181 | Gen: itay away-iriray ongsay-incay-incay isishay orkway-orkway\n",
            "Epoch:  12 | Train loss: 0.697 | Val loss: 0.990 | Gen: etay airway onmingingingway ishay orkingway\n",
            "Epoch:  13 | Train loss: 0.612 | Val loss: 0.875 | Gen: etay away-irway onmingingingway ishay orkingway\n",
            "Epoch:  14 | Train loss: 0.551 | Val loss: 0.860 | Gen: ethay away-irway onmingingingway ishay ongway\n",
            "Epoch:  15 | Train loss: 0.522 | Val loss: 0.772 | Gen: ethay away-irway ondingingingway isway orkingway\n",
            "Epoch:  16 | Train loss: 0.487 | Val loss: 0.756 | Gen: ehay away-irway ongionday-iuionday isway orkingway\n",
            "Epoch:  17 | Train loss: 0.470 | Val loss: 0.933 | Gen: ethay airay-iray ongscay-ondingscay ishay orkingway\n",
            "Epoch:  18 | Train loss: 0.461 | Val loss: 0.790 | Gen: etay airway-irway ondingingsay isisway orkingway\n",
            "Epoch:  19 | Train loss: 0.415 | Val loss: 0.794 | Gen: ethay airway-irway ongingingway isway orkingway\n",
            "Epoch:  20 | Train loss: 0.443 | Val loss: 0.769 | Gen: etay airway-airway ongingway-indingway isway orkingway\n",
            "Epoch:  21 | Train loss: 0.458 | Val loss: 1.031 | Gen: ethay awayirway onwingingingway isisway orkingway-inway-inwa\n",
            "Epoch:  22 | Train loss: 0.448 | Val loss: 0.708 | Gen: ehay away-irray ongday isway orkrkray\n",
            "Epoch:  23 | Train loss: 0.383 | Val loss: 0.646 | Gen: ethay airway-irway ongway-indingway isway orkingway\n",
            "Epoch:  24 | Train loss: 0.340 | Val loss: 0.598 | Gen: ethay airway ongingway isway orkingway\n",
            "Epoch:  25 | Train loss: 0.324 | Val loss: 0.656 | Gen: ethay away-irway ongingcay isway orkingway\n",
            "Epoch:  26 | Train loss: 0.319 | Val loss: 0.669 | Gen: etay airway ongcay isway orkingway\n",
            "Epoch:  27 | Train loss: 0.321 | Val loss: 0.651 | Gen: ethay away-orway ongcay-inway-indonda isway orkingway\n",
            "Epoch:  28 | Train loss: 0.309 | Val loss: 0.545 | Gen: ethay airway ongingay isway orkingway\n",
            "Epoch:  29 | Train loss: 0.279 | Val loss: 0.553 | Gen: ethay away-away ongcay isway orkingway\n",
            "Epoch:  30 | Train loss: 0.272 | Val loss: 0.541 | Gen: ethay airway ongcay isway orkingway\n",
            "Epoch:  31 | Train loss: 0.262 | Val loss: 0.515 | Gen: ethay away-away ongcay isway orkingway\n",
            "Epoch:  32 | Train loss: 0.252 | Val loss: 0.517 | Gen: ethay away-airway ongcay isway orkingway\n",
            "Epoch:  33 | Train loss: 0.272 | Val loss: 0.697 | Gen: ethay airwaypray ongongongay isway orkingway\n",
            "Epoch:  34 | Train loss: 0.302 | Val loss: 0.601 | Gen: ethay airway ongcay isway orkway-inway\n",
            "Epoch:  35 | Train loss: 0.269 | Val loss: 0.533 | Gen: ethay airway ongcay isway orkingway\n",
            "Epoch:  36 | Train loss: 0.245 | Val loss: 0.495 | Gen: ethay airway ongcay isway orkingway\n",
            "Epoch:  37 | Train loss: 0.232 | Val loss: 0.506 | Gen: ethay airway ongcay isway orkingway\n",
            "Epoch:  38 | Train loss: 0.229 | Val loss: 0.537 | Gen: ethay away-irway ongongcay isway orkingway\n",
            "Epoch:  39 | Train loss: 0.225 | Val loss: 0.496 | Gen: ethay airway ongcay isway orkingway\n",
            "Epoch:  40 | Train loss: 0.220 | Val loss: 0.499 | Gen: ethay airway ongcay isway orkway-inway\n",
            "Epoch:  41 | Train loss: 0.218 | Val loss: 0.525 | Gen: ethay away-away ongcay isway orkingway\n",
            "Epoch:  42 | Train loss: 0.225 | Val loss: 0.520 | Gen: ethay away ondingcay isway orkingway\n",
            "Epoch:  43 | Train loss: 0.211 | Val loss: 0.493 | Gen: ethay airway ondingway isway orkingway\n",
            "Epoch:  44 | Train loss: 0.203 | Val loss: 0.486 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  45 | Train loss: 0.200 | Val loss: 0.482 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  46 | Train loss: 0.202 | Val loss: 0.544 | Gen: ethay away-irway ondingway isway orkingway\n",
            "Epoch:  47 | Train loss: 0.217 | Val loss: 0.505 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  48 | Train loss: 0.220 | Val loss: 0.598 | Gen: ethay away-irway onditititionday isway orkway-inway\n",
            "Epoch:  49 | Train loss: 0.213 | Val loss: 0.483 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  50 | Train loss: 0.190 | Val loss: 0.492 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  51 | Train loss: 0.186 | Val loss: 0.493 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  52 | Train loss: 0.188 | Val loss: 0.522 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  53 | Train loss: 0.193 | Val loss: 0.495 | Gen: ethay away-airway ondingway isway orkingway\n",
            "Epoch:  54 | Train loss: 0.193 | Val loss: 0.565 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  55 | Train loss: 0.232 | Val loss: 0.571 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  56 | Train loss: 0.217 | Val loss: 0.482 | Gen: ethay airway oningway isway orkingway\n",
            "Epoch:  57 | Train loss: 0.188 | Val loss: 0.479 | Gen: ethay airway ongway isway orkingway\n",
            "Epoch:  58 | Train loss: 0.175 | Val loss: 0.428 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  59 | Train loss: 0.163 | Val loss: 0.440 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  60 | Train loss: 0.160 | Val loss: 0.435 | Gen: ethay airway ondingway isway orkingway\n",
            "Epoch:  61 | Train loss: 0.156 | Val loss: 0.446 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  62 | Train loss: 0.155 | Val loss: 0.439 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  63 | Train loss: 0.153 | Val loss: 0.443 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  64 | Train loss: 0.151 | Val loss: 0.444 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  65 | Train loss: 0.148 | Val loss: 0.446 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  66 | Train loss: 0.148 | Val loss: 0.447 | Gen: ethay airway ondingwingway isway orkingway\n",
            "Epoch:  67 | Train loss: 0.147 | Val loss: 0.460 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  68 | Train loss: 0.154 | Val loss: 0.533 | Gen: ethay airway ondingway isway orkingway\n",
            "Epoch:  69 | Train loss: 0.178 | Val loss: 0.541 | Gen: ethay airway oningcay isway orkingway\n",
            "Epoch:  70 | Train loss: 0.205 | Val loss: 0.572 | Gen: ethay away ondingcay isway orkingway\n",
            "Epoch:  71 | Train loss: 0.275 | Val loss: 0.634 | Gen: eway airway ondingingway isway orkingway\n",
            "Epoch:  72 | Train loss: 0.246 | Val loss: 0.485 | Gen: ethay away-ay oningingcay isway orkingway\n",
            "Epoch:  73 | Train loss: 0.179 | Val loss: 0.433 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  74 | Train loss: 0.157 | Val loss: 0.397 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  75 | Train loss: 0.147 | Val loss: 0.388 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  76 | Train loss: 0.140 | Val loss: 0.388 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  77 | Train loss: 0.136 | Val loss: 0.389 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  78 | Train loss: 0.134 | Val loss: 0.388 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  79 | Train loss: 0.131 | Val loss: 0.391 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  80 | Train loss: 0.130 | Val loss: 0.395 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  81 | Train loss: 0.128 | Val loss: 0.397 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  82 | Train loss: 0.127 | Val loss: 0.398 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  83 | Train loss: 0.126 | Val loss: 0.409 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  84 | Train loss: 0.125 | Val loss: 0.406 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  85 | Train loss: 0.124 | Val loss: 0.415 | Gen: ethay airway onditingcay isway orkingway\n",
            "Epoch:  86 | Train loss: 0.125 | Val loss: 0.407 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  87 | Train loss: 0.122 | Val loss: 0.421 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  88 | Train loss: 0.122 | Val loss: 0.418 | Gen: ethay airway oningcay isway orkingway\n",
            "Epoch:  89 | Train loss: 0.121 | Val loss: 0.409 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  90 | Train loss: 0.119 | Val loss: 0.414 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  91 | Train loss: 0.118 | Val loss: 0.416 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  92 | Train loss: 0.119 | Val loss: 0.417 | Gen: ethay airway oningcay isway orkingway\n",
            "Epoch:  93 | Train loss: 0.118 | Val loss: 0.437 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  94 | Train loss: 0.124 | Val loss: 0.434 | Gen: ethay airway onditingcay isway orkingway\n",
            "Epoch:  95 | Train loss: 0.124 | Val loss: 0.447 | Gen: ethay airway oningcay isway orkingway\n",
            "Epoch:  96 | Train loss: 0.124 | Val loss: 0.466 | Gen: ethay airway ondititingcay isway orkingway\n",
            "Epoch:  97 | Train loss: 0.130 | Val loss: 0.487 | Gen: ethay away ondingcay isway orkingway\n",
            "Epoch:  98 | Train loss: 0.137 | Val loss: 0.522 | Gen: ethay airway ondingcay isway orkingway\n",
            "Epoch:  99 | Train loss: 0.154 | Val loss: 0.501 | Gen: ethay away oningcay isway orkingway\n",
            "source:\t\tthe air conditioning is working \n",
            "translated:\tethay away oningcay isway orkingway\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfgbnfyVEPRs"
      },
      "source": [
        "**If you compare both the Train loss, Validation loss of the GRU model vs the Attention model you'll see that the loss is significantly decreased and the Test translated sentence is more accurate in the Attention model.**\n",
        "\n",
        "**Activation function used is tanh mainly for long sentences**\n",
        "\n",
        "**Bidirectional LSTM's can also be implemented for long sentence translation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9DGS1QLk9GP"
      },
      "source": [
        "# **Q4.If you input a very long sentence, do you have problem of translation this sentence? If so, what could be potentially the problem? Write down the answer.**\n",
        "\n",
        "The reason to why a simple RNN wouldn't work for a long sentence transalation is due to its vanishing gradient problem. It makes the training of a simple RNN's very slow and inefficient for usage is vanishing gradient issue. Small gradients tends to diminish by large margins after every layer and reach a point where they are very close to zero hence the learning drops for initial layers and overall effective training slows down.\n",
        "\n",
        " Hence, Due to vanishing gradients in the backpropagation step of computing the error backwards for improvement, normal RNNs are quite problematic when input sequences are long. While they show good results for shorter sequences, in longer ones the distance between the relevant words can be too long for results to be acceptable.\n",
        "\n",
        " Additionally, When we consider the long sentences model will not perform well. The reason is that the architecture uses a fixed-length vector hT to represent the input sequence, and hT is the only information decoder can get.\n",
        "For a long sequence, hT won’t be enough to represent all information of the input sequence. With a information loss, the decoder won’t be able to make accurate character-wise predictions. Alongside the distance between the input character and output character is always far to away"
      ]
    }
  ]
}
